const system = 
`you are an exam creator you will create an exam following the good exam creation principles from well known books following this 
format: {formatInstruction}
you will generate at least {nbrOfExercice} Exercice
`
const user = "here is the content you will generate the exam for {content} "
const personalBook = 
"Designing exams & questions that trigger memorisation Goal: A practical, evidence-based handbook for creating exams, exercises and questions that improve long term retention, transfer and meaningful learning — not just measure it. This document summarizes key cognitive-science principles, gives concrete question-writing recipes for different formats (MCQ, fill-in, flashcard, yes/no, prompt-based), and provides ready-to-use blueprints (exam blueprint, spacing schedules, feedback rubrics). At-a-glance principles (what reliably helps memory) 1. 2. 3. 4. 5. 6. 7. 8. Retrieval practice (testing effect) — having learners try to recall information strengthens long term retention more than passive review. Make exams include retrieval tasks, not just recognition. Spacing (distributed practice) — spread practice and tests over time rather than massing them into one session; this produces much better retention. Interleaving & variability — mix related topics and vary problem contexts; this helps discrimination and transfer. Desirable difficulties — make tasks slightly harder (e.g., omit hints, use recall instead of recognition) but still achievable; this improves encoding and retrieval. Generation & elaboration — require learners to produce or explain answers (generation) and connect new info to prior knowledge (elaboration) to deepen encoding. Timely, specific feedback — feedback corrects errors and strengthens memory; immediate feedback is helpful for novices, while delayed feedback can foster retrieval for those with some prior knowledge. Cognitive load management — keep item wording clear and avoid unnecessary complexity that distracts from the targeted knowledge. Practice testing with variation — repeated low-stakes quizzes, varied formats, and cumulative reviews outperform single high-stakes tests. 1 How to translate principles into exam design 1) Build retrieval into every assessment • • Prefer short-answer / fill-in-the-blank and flashcards for pure recall training. Use MCQs that require application or problem-solving (not pure recognition). Avoid cues that let students guess without true retrieval. 2) Design a spaced testing schedule • • Plan low-stakes quizzes distributed across the course (e.g., weekly micro-quizzes + cumulative quiz every 3–4 weeks). Pair immediate practice with later cumulative retrieval opportunities (forward-testing helps learning of later material). 3) Interleave related topics • • Instead of dedicated blocks for one topic, mix practice problems from several topics in each quiz. For problem-solving skills, alternate different problem types so students learn to choose the right strategy. 4) Make questions \"desirably difficult\" • • Increase difficulty via partial prompts, requiring generation, or removing scaffolds. Avoid making items impossible; ensure learners have enough prior exposure. 5) Use feedback strategically • • After a retrieval attempt, provide answer feedback plus a short explanation or worked example. For low-stakes retrieval, let learners attempt first, then reveal answers and brief rationale. 6) Manage cognitive load • • Keep stems concise and focus each item on a single target concept. Avoid overly long vignettes or extraneous data unless the learning goal is to interpret complex stimuli. Question-type recipes (how to write items that promote memorisation) Flashcards • • • Goal: rapid retrieval practice for discrete facts/concepts. How to write: single focused prompt on front; concise, specific answer on back; include a short mnemonic or elaboration on the back. Use: repeated spaced review; integrate into weekly micro-quizzes. 2 Sample: Front: \"Define 'event loop' in JavaScript (one sentence).\" Back: \"A loop that pulls tasks from the message queue and processes callbacks, allowing non-blocking I/O.\" Fill-in / Short-answer • • • Goal: high-quality recall (generation). How to write: target a single fact or short concept; avoid multiple distinct answers unless synonyms are accepted. Provide acceptable-answer list and minor-spelling tolerance. Use: pre-class or online low-stakes quizzes. Sample: \"Complete: HTTP status 200 means ______.\" (Answer: \"OK\" or \"Success\") Multiple-choice (MCQ) • • • • • • • Goal: assess understanding and application while controlling scoring reliability. How to write good MCQs: Use a clear stem that asks about one idea. Put the problem in the stem, keep options short. Have one best answer; distractors should be plausible and drawn from common misconceptions. Use scenario stems for higher-order thinking (application, analysis). Design tip: write MCQs while planning lessons; align each item to a specific learning objective. Sample (application-level): \"Given this DOM snippet, which event fires when the user leaves the text field?\" Options include plausible misconceptions. Yes/No • • Goal: quick concept checks; use sparingly because chance-level guessing is 50%. How to write: prefer forced-choice paired with justification or follow-up short answer to avoid guessing. Sample: \"True or False: CSS specificity is solved by the later rule in the stylesheet.\" Follow-up: \"Explain why or give a counterexample.\" Open response / Essay • • Goal: synthesis, explanation, transfer. How to write: give a clear rubric, ask for specific steps or reasoning, and grade using analytic criteria. Provide model answers to support feedback. Blueprints, blueprints, blueprints 1-page exam blueprint (example for a 30-question midterm) • • • 10 recall (fill-in/short answer) — 30% of grade (tests core facts) 12 MCQs (application/analysis) — 40% 3 short problems (explain a solution) — 20% 3 5 flashcards / quick prompts (ungraded, for in-class retrieval) — formative • Why: recall items strengthen long-term retention; MCQs assess application; short problems require generation and elaboration. Spacing templates (practical) • • • • • Intro to concept (Day 0). Initial study + immediate retrieval (quick quiz). Early review (Day 1–2). Short retrieval quiz. First spaced interval (Day 7). Cumulative quiz that mixes topics. Second spaced interval (Day 21–28). Cumulative mid-term quiz. Long-term review (1–3 months). Final cumulative exam and optional spaced flashcards. Adjust intervals by difficulty and student prior knowledge. Scoring & feedback recommendations • • • Use low-stakes frequent testing to encourage retrieval without high pressure. Provide automated immediate feedback for objective items and detailed teacher feedback for constructed responses. Offer model answers and short worked examples after attempts to consolidate learning. Practical checklist for each item • • • • • • Is the learning objective clear? Is the item focused on one concept? Does the format require retrieval rather than recognition? Is the difficulty appropriate (desirable difficulty)? Are distractors plausible and based on common misconceptions (MCQ)? Is feedback planned for after the attempt? Sample exam (mini) • • • • 5 fill-in (definitions) 8 MCQ (application) 2 short problems (explain & justify) 5 flashcards for spaced review Implementation tips for digital platforms • Randomize order of items and options to minimize pattern guessing. 4 • • Record metadata per item (time to answer, correct/incorrect) to build adaptive spacing schedules. Provide learners an exportable flashcard set for self-study. Quick references & further reading (Use these to dive deeper into each principle and the evidence base.) • • • Retrieval practice / testing effect — include retrieval activities regularly. Spacing & distributed practice — schedule reviews over days and weeks. Desirable difficulties — make tasks effortful but achievable. Appendix: example question templates • • • MCQ stem + 4 distractors. Fill-in with acceptable answers and synonyms. Flashcard front/back with mnemonic"
const explanation = "for the generated exam i want you to generate some explanation following good explanation pratice from well know books following this format: {formatInstruction} " 

const prompt = {
    system: system,
    user: user,
    book: personalBook,
    explanation: explanation,
}
export default prompt